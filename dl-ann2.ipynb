{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport numpy as np\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n#注意此处类型转化为float，不然后面求导会报错\ntrain = pd.read_csv('digit-recognizer/train.csv', dtype=np.float32)\n\n#获取x，y\ny = train.label.values\nx = train.loc[:, train.columns!='label'].values / 255\n\n#注意是这四个顺序，获得训练集测试集\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2019)\n\n#转化为tensor，注意这里y要转为longtensor，因为是进行交叉熵loss计算\nx_train = torch.from_numpy(x_train)\ny_train = torch.from_numpy(y_train).type(torch.LongTensor)\n\nx_test = torch.from_numpy(x_test)\ny_test = torch.from_numpy(y_test).type(torch.LongTensor)\n\n#batch size 和 轮数\nbatch_size = 128\niteration_num = 100\n\n\n'''\ntorch.utils.data.TensorDataset用于将训练集x，y合并\n'''\ntrain = torch.utils.data.TensorDataset(x_train, y_train)\ntest = torch.utils.data.TensorDataset(x_test, y_test)\n\n'''\nDataLoader用于随机播放和批量处理数据。\n它可用于与多处理工作程序并行加载数据\n在dataset基础上多了batch_size, shuffle等操作\n'''\ntrain_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)\n\n\n\nclass ANNModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(ANNModel, self).__init__()\n\t\t#定义层\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.relu1 = nn.ReLU() #nn.Linear为线性关系，加上激活函数转为非线性\n        \n        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n        self.relu2 = nn.ReLU()\n        \n        self.fc3 = nn.Linear(hidden_dim, output_dim)\n        \n        \n    def forward(self, x):\n        out = self.fc1(x)\n        out = self.relu1(out)\n        out = self.fc2(out)\n        out = self.relu2(out)\n        out = self.fc3(out)\n        return out\n    \ninput_dim = 28*28   #一维向量长度\nhidden_dim = 128 #hidden layer 神经元个数\noutput_dim = 10  #10个类\n\nmodel = ANNModel(input_dim, hidden_dim, output_dim)\nCrossEntropyLoss = nn.CrossEntropyLoss()\n\nloss_list = []\n\nlearning_rate = 0.001\noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n\n\nfor iteration in range(iteration_num):\n    for j, (images, labels) in enumerate(train_loader):\n        #将其转化为变量\n        train = Variable(images.view(-1, 28*28))\n        labels = Variable(labels)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(train)\n        loss = CrossEntropyLoss(outputs, labels)\n        loss.backward()\n        optimizer.step()\n       \n        '''\n        验证集accuracy计算\n        '''\n        if j % 50 == 0:\n            \n            correct = 0\n            total = 0\n            \n            for images, labels in test_loader:\n                test = Variable(images.view(-1, 28*28))\n                \n                outputs = model(test)\n                prediction = torch.max(outputs.data, 1)[1]\n                \n                total += len(labels)\n                correct += (prediction == labels).sum()\n            \n            accuracy = 100 * correct / float(total)\n            loss_list.append(loss.data)\n            \n    if iteration % 50 ==0:\n        print('Epoch:{} Loss:{} Accuracy:{}'.format(iteration, loss.data, accuracy)) ","metadata":{},"execution_count":null,"outputs":[]}]}