{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Google的T5模型从2019年发布到今天雄风依旧；在翻译，文本分类，智能问答，文章摘要等方面都取得SOTA地位；本文使用T5的翻译功能完成 文本从一种语言翻译到另一种语言的翻译功能，我们可以使用把模型最后输出的目标语音文本代回到google翻译器中进行进一步验证，来判断T5模型的翻译功能效果。\n# 一、目标文本是什么？\n\n# 为了方便T5模型的训练，我们这里采用两句自己定义的英文文本，当然读者也可以自己定义相关句子；本文的目标文本为英语，目标文本为法语；\n# 【注意：输入文本为list格式，元素为str格式；同时在task_prefix 定义翻译原文语言和目标语言】\n\n#suppose we have the following 2 training examples\ninput_sequence_2 = \"My eyes fill you with love\"\ninput_sequence_3 = \"He is pretty kind that I did not expect\"\ninput_sequence_4 = \"Her eyes are blue\"\n\n\n# 然后我们把它转化为list形式\n\ntask_prefix = \"translate English to French: \"\ninput_sequences = [input_sequence_2]\ninput_sequences.extend([input_sequence_3, input_sequence_4])","metadata":{"execution":{"iopub.status.busy":"2023-10-16T15:57:45.793006Z","iopub.execute_input":"2023-10-16T15:57:45.793417Z","iopub.status.idle":"2023-10-16T15:57:45.834570Z","shell.execute_reply.started":"2023-10-16T15:57:45.793382Z","shell.execute_reply":"2023-10-16T15:57:45.833524Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"input_sequences","metadata":{"execution":{"iopub.status.busy":"2023-10-16T16:00:42.758434Z","iopub.execute_input":"2023-10-16T16:00:42.759309Z","iopub.status.idle":"2023-10-16T16:00:42.766879Z","shell.execute_reply.started":"2023-10-16T16:00:42.759254Z","shell.execute_reply":"2023-10-16T16:00:42.766016Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['My eyes fill you with love',\n 'He is pretty kind that I did not expect',\n 'Her eyes are blue']"},"metadata":{}}]},{"cell_type":"code","source":"# 二、模型调用步骤\n# 1.引入库\n# pip install torch==1.7.0+cu110 torchvision==0.8.1+cu110 torchaudio===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n\n# 1.2 在python脚本中写入引入库的相关代码，如下\n\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nimport torch\n\n\n# 2.导入模型，本文使用 t5-base\n\ntokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\nmodel = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n#task specific parameter\nmax_source_length = 512","metadata":{"execution":{"iopub.status.busy":"2023-10-16T15:57:45.837592Z","iopub.execute_input":"2023-10-16T15:57:45.838875Z","iopub.status.idle":"2023-10-16T15:58:11.500067Z","shell.execute_reply.started":"2023-10-16T15:57:45.838838Z","shell.execute_reply":"2023-10-16T15:58:11.499064Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ff7e46ff63649008ed58a20cc0ff3ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcb8ae6797b444c38bc39cb2fffa4ba9"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:220: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\nFor now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n  warnings.warn(\nYou are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96b23bb978f241d2921f0067dba73437"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b148da09773b4718aad1628b1c5119be"}},"metadata":{}}]},{"cell_type":"code","source":"# 3.使用分词器对目标文本进行分词\n\nencoding = tokenizer([task_prefix + sequence for sequence in input_sequences]\n                    , padding = True\n                    , return_tensors=\"pt\").input_ids","metadata":{"execution":{"iopub.status.busy":"2023-10-16T15:58:11.501199Z","iopub.execute_input":"2023-10-16T15:58:11.501523Z","iopub.status.idle":"2023-10-16T15:58:12.229790Z","shell.execute_reply.started":"2023-10-16T15:58:11.501495Z","shell.execute_reply":"2023-10-16T15:58:12.228175Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"encoding","metadata":{"execution":{"iopub.status.busy":"2023-10-16T15:59:54.778483Z","iopub.execute_input":"2023-10-16T15:59:54.778878Z","iopub.status.idle":"2023-10-16T15:59:54.789970Z","shell.execute_reply.started":"2023-10-16T15:59:54.778851Z","shell.execute_reply":"2023-10-16T15:59:54.788937Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"tensor([[13959,  1566,    12,  2379,    10,   499,  2053,    14,    25,    28,\n           333,     1,     0,     0,     0],\n        [13959,  1566,    12,  2379,    10,   216,    19,  1134,   773,    24,\n            27,   410,    59,  1672,     1],\n        [13959,  1566,    12,  2379,    10,  1347,  2053,    33,  1692,     1,\n             0,     0,     0,     0,     0]])"},"metadata":{}}]},{"cell_type":"code","source":"# 4.对刚刚生成的分词结果进行目标语言的生成工作\n\noutputs = model.generate(encoding)\n\n\n# 5.对生成的目标语言进行解码工作，就可得到目标语言的文本，并打印\n\nresult = tokenizer.batch_decode(outputs, skip_special_tokens = True)\nprint(result)\n\n    \n# 结果如下，\n\n# [\"Mes yeux vous remplissent d'amour\", 'Il est assez gentil que je ne m’attendais pas à', 'Ses yeux sont bleus']\n\n\n# 通过google检验：即再把法语翻译为英语，结果如下\n\n\n# 完全一致！当然，因为法语是不分性别的，也就是他/她 不分，所以小伙伴们可能翻译的最终结果是 Her而不是His","metadata":{"execution":{"iopub.status.busy":"2023-10-16T16:00:12.984195Z","iopub.execute_input":"2023-10-16T16:00:12.984607Z","iopub.status.idle":"2023-10-16T16:00:14.572443Z","shell.execute_reply.started":"2023-10-16T16:00:12.984575Z","shell.execute_reply":"2023-10-16T16:00:14.571248Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[\"Mes yeux vous remplissent d'amour\", 'Il est assez gentil que je ne m’attendais pas à', 'Ses yeux sont bleus']\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}