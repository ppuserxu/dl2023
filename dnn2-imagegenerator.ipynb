{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch, time, os\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision.datasets import MNIST\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import save_image\nimport torch.nn.functional as F\n \n ","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:29:10.278895Z","iopub.execute_input":"2023-10-01T15:29:10.280197Z","iopub.status.idle":"2023-10-01T15:29:14.614640Z","shell.execute_reply.started":"2023-10-01T15:29:10.280149Z","shell.execute_reply":"2023-10-01T15:29:14.613712Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class DNN(nn.Module):\n    def __init__(self, input_dim=100, output_dim=1, class_num=10):\n        '''\n        初始化网络\n        :param input_dim:输入维度，也是latent维度\n        :param output_dim:输出维度，表示最终生成图片的通道数\n        :param class_num:图像种类，代表condition种类\n        '''\n        super(DNN, self).__init__()\n        # 网络的输入是latent的维度拼接上condition向量的维度\n        self.input_dim = input_dim + class_num\n        self.output_dim = output_dim\n \n        self.fc = nn.Sequential(\n            nn.Linear(self.input_dim, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Linear(1024, 128 * 7 * 7),\n            nn.BatchNorm1d(128 * 7 * 7),\n            nn.ReLU(),\n        )\n        self.deconv = nn.Sequential(\n            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n            nn.Sigmoid(),\n        )\n \n    def forward(self, input):\n        x = self.fc(input)\n        x = x.view(-1, 128, 7, 7)\n        x = self.deconv(x)\n        return x\n \n \nclass ImageGenerator(object):\n    def __init__(self):\n        '''\n        初始化，定义超参数、数据集、网络结构等\n        '''\n        self.epoch = 5\n        self.sample_num = 100\n        self.batch_size = 64\n        self.z_dim = 62\n        self.lr = 0.0001\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        self.init_dataloader()\n        self.model = DNN(input_dim=self.z_dim, output_dim=self.output_dim).to(self.device)\n        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n        self.loss = nn.MSELoss().to(self.device)\n \n    def init_dataloader(self):\n        '''\n        初始化数据集和dataloader\n        '''\n        tf = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize((0.1307,), (0.3081,))\n        ])\n        train_dataset = MNIST('./data/',\n                              train=True,\n                              download=True,\n                              transform=tf)\n        self.train_dataloader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, drop_last=True)\n        val_dataset = MNIST('./data/',\n                            train=False,\n                            download=True,\n                            transform=tf)\n        self.val_dataloader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n        self.output_dim = self.train_dataloader.__iter__().__next__()[0].shape[1]\n \n    def train(self):\n        self.model.train()\n        print('训练开始!!')\n        for epoch in range(self.epoch):\n            self.model.train()\n            loss_mean = 0\n            for i, (images, labels) in enumerate(self.train_dataloader):\n                # 生成对应batch和维度的latent\n                z = torch.rand((self.batch_size, self.z_dim)).to(self.device)\n                images, labels = images.to(self.device), labels.to(self.device)\n                # 将原始label做one hot后作为condition向量\n                labels = F.one_hot(labels, num_classes=10)\n                self.optimizer.zero_grad()\n                # 将latent和condition拼接后输入网络\n                generated_images = self.model(torch.cat((z, labels), dim=1))\n                loss = self.loss(generated_images, images)\n                loss_mean += loss.item()\n                loss.backward()\n                self.optimizer.step()\n            train_loss = loss_mean / len(self.train_dataloader)\n            val_loss = self.evaluation()\n            print('epoch:{}, training loss:{:.4f}, validation loss:{:.4f}'.format(epoch, train_loss, val_loss))\n            self.visualize_results(epoch)\n \n    @torch.no_grad()\n    def evaluation(self):\n        self.model.eval()\n        loss_mean = 0\n        for i, (images, labels) in enumerate(self.val_dataloader):\n            # 生成对应image batch和维度的latent\n            z = torch.rand((images.shape[0], self.z_dim)).to(self.device)\n            images, labels = images.to(self.device), labels.to(self.device)\n            # 将原始label做one hot后作为condition向量\n            labels = F.one_hot(labels, num_classes=10)\n            # 将latent和condition拼接后输入网络\n            generated_images = self.model(torch.cat((z, labels), dim=1))\n            loss = self.loss(generated_images, images)\n            loss_mean += loss.item()\n        return loss_mean / len(self.val_dataloader)\n \n    @torch.no_grad()\n    def visualize_results(self, epoch):\n        self.model.eval()\n        # 保存结果路径\n        output_path = 'results/DNN'\n        if not os.path.exists(output_path):\n            os.makedirs(output_path)\n \n        tot_num_samples = self.sample_num\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n \n        z = torch.rand((tot_num_samples, self.z_dim)).to(self.device)\n        # 生成对应sample个condition向量，每十个sample为一类\n        labels = F.one_hot(torch.Tensor(np.repeat(np.arange(10), 10)).to(torch.int64), num_classes=10).to(self.device)\n        generated_images = self.model(torch.cat((z, labels), dim=1))\n        save_image(generated_images, os.path.join(output_path, '{}.jpg'.format(epoch)), nrow=image_frame_dim)\n \n ","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:29:14.617216Z","iopub.execute_input":"2023-10-01T15:29:14.617780Z","iopub.status.idle":"2023-10-01T15:29:14.640166Z","shell.execute_reply.started":"2023-10-01T15:29:14.617748Z","shell.execute_reply":"2023-10-01T15:29:14.639127Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"generator = ImageGenerator()\ngenerator.train()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:29:14.641198Z","iopub.execute_input":"2023-10-01T15:29:14.641582Z","iopub.status.idle":"2023-10-01T15:39:46.288158Z","shell.execute_reply.started":"2023-10-01T15:29:14.641553Z","shell.execute_reply":"2023-10-01T15:39:46.286999Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 105875475.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 103712066.63it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 1648877/1648877 [00:00<00:00, 29594930.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 10601295.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\n训练开始!!\nepoch:0, training loss:0.7723, validation loss:0.7196\nepoch:1, training loss:0.7148, validation loss:0.7134\nepoch:2, training loss:0.7112, validation loss:0.7113\nepoch:3, training loss:0.7096, validation loss:0.7106\nepoch:4, training loss:0.7089, validation loss:0.7099\n","output_type":"stream"}]}]}